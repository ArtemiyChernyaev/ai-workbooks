{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0683e18",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414680f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n",
      "0.8757270529783324\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "    \n",
    "class FirstNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        \n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2= self.h2.feedforward(x)\n",
    "        out_h3= self.h3.feedforward(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1,out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "\n",
    "class SecondNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        \n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2= self.h2.feedforward(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1,out_h2]))\n",
    "        out_o2 = self.o1.feedforward(np.array([out_h1,out_h2]))\n",
    "        \n",
    "        return out_o1\n",
    "\n",
    "    \n",
    "network_1 = FirstNeuralNetwork()\n",
    "network_2 = SecondNeuralNetwork()\n",
    "x_1 = np.array([2, 3, 4])\n",
    "x_2 = np.array([2, 3])\n",
    "print(network_1.feedforward(x_1))\n",
    "print(network_2.feedforward(x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c80e62",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a5a85cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9050813365686774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "    \n",
    "    \n",
    "class TanhNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        \n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2= self.h2.feedforward(x)\n",
    "        out_h3= self.h3.feedforward(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1,out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "    \n",
    "network = TanhNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ed3a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "class Neuron:\n",
    "    \n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return ReLU(total)\n",
    "    \n",
    "    \n",
    "class ReLUNeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        \n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2= self.h2.feedforward(x)\n",
    "        out_h3= self.h3.feedforward(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1,out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "    \n",
    "network = ReLUNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f8e5c",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1902056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Versicolor' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa'\n",
      " 'Virginica' 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Versicolor'\n",
      " 'Virginica' 'Versicolor' 'Virginica']\n",
      "80     Versicolor\n",
      "45         Setosa\n",
      "144     Virginica\n",
      "110     Virginica\n",
      "38         Setosa\n",
      "2          Setosa\n",
      "135     Virginica\n",
      "72     Versicolor\n",
      "138     Virginica\n",
      "34         Setosa\n",
      "19         Setosa\n",
      "77     Versicolor\n",
      "101     Virginica\n",
      "63     Versicolor\n",
      "117     Virginica\n",
      "Name: variety, dtype: object\n",
      "Test Accuracy : 0.933\n",
      "Training Accuracy : 0.983\n",
      "Loss :  0.2988789340197434\n",
      "Number of Coefs :  2\n",
      "Number of Intercepts :  2\n",
      "Number of Iterations for Which Estimator Ran :  200\n",
      "Name of Output Layer Activation Function :  softmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yimetra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "digits  = pd.read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\")\n",
    "X_digits, Y_digits  = digits[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']], digits['variety']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, \n",
    "                                                    Y_digits, \n",
    "                                                    train_size = 0.8, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    stratify=Y_digits, \n",
    "                                                    random_state = 123)\n",
    "\n",
    "mlp_classifier =  MLPClassifier(random_state = 123)\n",
    "mlp_classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(Y_test[:15])\n",
    "\n",
    "print('Test Accuracy : %.3f'%mlp_classifier.score(X_test, Y_test))\n",
    "print('Training Accuracy : %.3f'%mlp_classifier.score(X_train, Y_train))\n",
    "\n",
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(2), range(2))\n",
    "    plt.xticks(range(2), range(2))\n",
    "    plt.colorbar();\n",
    "    \n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(i-0.2, j+0.1, str(conf_mat[j, i]), color='tab:red')\n",
    "    \n",
    "plot_confusion_matrix(Y_test, mlp_classifier.predict(X_test))\n",
    "\n",
    "print(\"Loss : \", mlp_classifier.loss_)\n",
    "print(\"Number of Coefs : \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of Intercepts : \", len(mlp_classifier.intercepts_))\n",
    "print(\"Number of Iterations for Which Estimator Ran : \", mlp_classifier.n_iter_)\n",
    "print(\"Name of Output Layer Activation Function : \", mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d4c38052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_preds: 20.262346279647666\n",
      "Y_preds: 55.278175202717804\n",
      "Y_preds: 18.821358115608366\n",
      "Y_preds: 50.482744871594164\n",
      "Y_preds: 20.262346279647666\n",
      "Y_preds: 50.96228790470653\n",
      "Y_test: 54445.0\n",
      "Y_test: 121872.0\n",
      "Y_test: 56642.0\n",
      "Y_test: 116969.0\n",
      "Y_test: 64445.0\n",
      "Y_test: 112635.0\n",
      "Test Accuracy : -8.796\n",
      "Training Accuracy : -8.261\n",
      "Loss :  2988058032.1601596\n",
      "Number of Coefs :  2\n",
      "Number of Intercepts :  2\n",
      "Number of Iterations for Which Estimator Ran :  200\n",
      "Name of Output Layer Activation Function :  identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yimetra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "digits  = pd.read_csv(\"https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv\")\n",
    "X_digits, Y_digits  = digits['YearsExperience'], digits['Salary']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, \n",
    "                                                    Y_digits, \n",
    "                                                    train_size = 0.8, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 123)\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "X_test = X_test.values.reshape(-1,1)\n",
    "\n",
    "\n",
    "mlp_regressor =  MLPRegressor(random_state = 123)\n",
    "mlp_regressor.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "for i in Y_preds:\n",
    "    print('Y_preds:', i)\n",
    "    \n",
    "for i in Y_test:\n",
    "    print('Y_test:', i)\n",
    "\n",
    "print('Test Accuracy : %.3f'%mlp_regressor.score(X_test, Y_test))\n",
    "print('Training Accuracy : %.3f'%mlp_regressor.score(X_train, Y_train))\n",
    "\n",
    "print(\"Loss : \", mlp_regressor.loss_)\n",
    "print(\"Number of Coefs : \", len(mlp_regressor.coefs_))\n",
    "print(\"Number of Intercepts : \", len(mlp_regressor.intercepts_))\n",
    "print(\"Number of Iterations for Which Estimator Ran : \",mlp_regressor.n_iter_)\n",
    "print(\"Name of Output Layer Activation Function : \",mlp_regressor.out_activation_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
